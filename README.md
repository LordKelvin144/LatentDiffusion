Reproducing ["High-Resolution Image Synthesis with Latent Diffusion Models"](https://arxiv.org/abs/2112.10752) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj√∂rn Ommer.

# Running

### Training a simple diffusion model on MNIST
The script `mnist_diffusion.py` allows for training simple diffusion-only models (i.e. without latent embedding) for generating MNIST digits.

To train a model, one can invoke
```bash
python3 mnist_diffusion --train
```
which will produce checkpoints in `checkpoints/mnist`.

To showcase digits generated by a model, one can run
```bash
python3 mnist_diffusion --show checkpoints/mnist/epoch_X.safetensors
```
where the relevant path to the checkpoint is passed.

### Latent diffusion on the CelebA dataset
The main objective of this project is to generate realistic faces. I opted to use the [CelebA dataset](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html).

First, an autoencoder needs to be trained. To do this, run 
```bash
python3 train_encoder.py
```
While training, the program will output checkpoints in `checkpoints/autoencoder/` and diagnostic figures in `fig/autoencoder/`.

The relevant autoencoder checkpoints are used for subsequently training the denoiser. To train a denoiser using a given autoencoder, run
```bash
python3 train_latent_denoiser.py --train --encoder checkpoints/autoencoder/epoch_X.safetensors
```
While training, denoiser checpoints will be saved in `checkpoints/denoiser/` and diagnostic figures appear in `fig/denoiser/`. 
Note that to save time in the autoencoder inference, 

the encoded images are cached and saved to the `encoded_img` directory. This consumes ~5 GB of space per autoencoder that is cached. 

After training a denoiser, one can generate images using 
```bash
python3 train_latent_denoiser.py --show checkpoints/deniser/XXX.safetensors --encoder checkpoints/autoencoder/YYY.safetensors
```


